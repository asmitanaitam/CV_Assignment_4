{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-2261b444a149>:10: DeprecationWarning: LEFT is deprecated, use CAM_B or address camera by name  instead.\n",
      "  left.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
      "<ipython-input-3-2261b444a149>:11: DeprecationWarning: RIGHT is deprecated, use CAM_C or address camera by name  instead.\n",
      "  right.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n",
      "Left image captured and saved.\n",
      "Right image captured and saved.\n"
     ]
    }
   ],
   "source": [
    "import depthai as dai\n",
    "import cv2\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# Create nodes for left and right cameras\n",
    "left = pipeline.createMonoCamera()\n",
    "right = pipeline.createMonoCamera()\n",
    "left.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "right.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "left.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "right.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "\n",
    "# Create XLinkOut nodes to stream the frames to the host\n",
    "xout_left = pipeline.createXLinkOut()\n",
    "xout_right = pipeline.createXLinkOut()\n",
    "xout_left.setStreamName(\"left\")\n",
    "xout_right.setStreamName(\"right\")\n",
    "\n",
    "# Link camera outputs to XLinkOut inputs\n",
    "left.out.link(xout_left.input)\n",
    "right.out.link(xout_right.input)\n",
    "\n",
    "# Connect to the device and start the pipeline\n",
    "with dai.Device(pipeline) as device:\n",
    "    # Get output queues for both cameras\n",
    "    q_left = device.getOutputQueue(name=\"left\", maxSize=4, blocking=False)\n",
    "    q_right = device.getOutputQueue(name=\"right\", maxSize=4, blocking=False)\n",
    "\n",
    "    while True:\n",
    "        # Get frames from both cameras\n",
    "        in_left = q_left.tryGet()\n",
    "        in_right = q_right.tryGet()\n",
    "\n",
    "        if in_left is not None:\n",
    "            frame_left = in_left.getCvFrame()\n",
    "            cv2.imshow(\"Left Camera\", frame_left)\n",
    "\n",
    "        if in_right is not None:\n",
    "            frame_right = in_right.getCvFrame()\n",
    "            cv2.imshow(\"Right Camera\", frame_right)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('c'):  # Press 'c' to capture and save images\n",
    "            if in_left is not None:\n",
    "                cv2.imwrite('captured_image_left.jpg', frame_left)\n",
    "                print(\"Left image captured and saved.\")\n",
    "            if in_right is not None:\n",
    "                cv2.imwrite('captured_image_right.jpg', frame_right)\n",
    "                print(\"Right image captured and saved.\")\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stereo Calibration is successful. Parameters are being saved and displayed.\n",
      "Stereo Calibration RMS Error: 0.4757282931190589\n",
      "Left Camera Matrix:\n",
      "[[457.7812485    0.         321.28652356]\n",
      " [  0.         457.19514736 219.61268967]\n",
      " [  0.           0.           1.        ]]\n",
      "Right Camera Matrix:\n",
      "[[455.24197497   0.         317.10366051]\n",
      " [  0.         450.5034614  204.22159131]\n",
      " [  0.           0.           1.        ]]\n",
      "Left Distortion Coefficients:\n",
      "[[-1.51416933e-01  4.69484148e+00  4.94664667e-03  1.53374422e-03\n",
      "  -1.79273275e+01]]\n",
      "Right Distortion Coefficients:\n",
      "[[ 0.0479837   0.79993686  0.00443373  0.01964638 -1.39671349]]\n",
      "Rotation Matrix between cameras:\n",
      "[[ 9.99990319e-01  2.30553656e-04  4.39422559e-03]\n",
      " [-2.57522232e-04  9.99981131e-01  6.13769892e-03]\n",
      " [-4.39272761e-03 -6.13877111e-03  9.99971509e-01]]\n",
      "Translation Vector between cameras:\n",
      "[[-53.35643152]\n",
      " [ -0.10507009]\n",
      " [ -4.26484455]]\n",
      "Parameters saved to 'stereoParams.xml'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "\n",
    "# Chessboard settings\n",
    "chessboardSize = (7, 6)\n",
    "frameSize = (640, 480)\n",
    "square_size = 20  # Size of a chessboard square [mm]\n",
    "\n",
    "# Termination criteria for corner sub-pix\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Arrays to store object points and image points from all images.\n",
    "objpoints = []  # 3D point in real world space\n",
    "imgpointsL = []  # 2D points in image plane for the left camera\n",
    "imgpointsR = []  # 2D points in image plane for the right camera\n",
    "\n",
    "# Prepare object points\n",
    "objp = np.zeros((chessboardSize[0] * chessboardSize[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:chessboardSize[0], 0:chessboardSize[1]].T.reshape(-1, 2) * square_size\n",
    "\n",
    "# Directory containing stereo images\n",
    "pathLeft = 'E:\\GSU\\Course Work\\Computer Vision\\Assignment_4\\stereoLeft\\*.jpg'\n",
    "pathRight = 'E:\\GSU\\Course Work\\Computer Vision\\Assignment_4\\stereoRight\\*.jpg'\n",
    "\n",
    "imagesLeft = sorted(glob.glob(pathLeft))\n",
    "imagesRight = sorted(glob.glob(pathRight))\n",
    "\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "    grayL = cv.cvtColor(imgL, cv.COLOR_BGR2GRAY)\n",
    "    grayR = cv.cvtColor(imgR, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    retL, cornersL = cv.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv.findChessboardCorners(grayR, chessboardSize, None)\n",
    "\n",
    "    # If found, add object points, refine and add image points\n",
    "    if retL and retR:\n",
    "        objpoints.append(objp)\n",
    "        cornersL = cv.cornerSubPix(grayL, cornersL, (11, 11), (-1, -1), criteria)\n",
    "        cornersR = cv.cornerSubPix(grayR, cornersR, (11, 11), (-1, -1), criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "        imgpointsR.append(cornersR)\n",
    "\n",
    "# Calibrate the stereo camera system\n",
    "retL, cameraMatrixL, distL, rvecsL, tvecsL = cv.calibrateCamera(objpoints, imgpointsL, frameSize, None, None)\n",
    "retR, cameraMatrixR, distR, rvecsR, tvecsR = cv.calibrateCamera(objpoints, imgpointsR, frameSize, None, None)\n",
    "\n",
    "flags = cv.CALIB_FIX_INTRINSIC\n",
    "criteria_stereo = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Stereo calibration\n",
    "retStereo, cameraMatrixL, distL, cameraMatrixR, distR, R, T, E, F = cv.stereoCalibrate(\n",
    "    objpoints, imgpointsL, imgpointsR, cameraMatrixL, distL, cameraMatrixR, distR, grayL.shape[::-1], criteria_stereo, flags)\n",
    "\n",
    "# Stereo rectification\n",
    "rectify_scale = 1  # 0 for no scaling, 1 for full scaling\n",
    "RL, RR, PL, PR, Q, validRoiL, validRoiR = cv.stereoRectify(cameraMatrixL, distL, cameraMatrixR, distR, grayL.shape[::-1], R, T, None, None, None, None, None, rectify_scale)\n",
    "\n",
    "# Compute the undistortion and rectification transformation map\n",
    "mapL1, mapL2 = cv.initUndistortRectifyMap(cameraMatrixL, distL, RL, PL, grayL.shape[::-1], cv.CV_16SC2)\n",
    "mapR1, mapR2 = cv.initUndistortRectifyMap(cameraMatrixR, distR, RR, PR, grayR.shape[::-1], cv.CV_16SC2)\n",
    "\n",
    "# Display and save the stereo calibration parameters\n",
    "print(\"Stereo Calibration is successful. Parameters are being saved and displayed.\")\n",
    "print(f\"Stereo Calibration RMS Error: {retStereo}\")\n",
    "print(f\"Left Camera Matrix:\\n{cameraMatrixL}\")\n",
    "print(f\"Right Camera Matrix:\\n{cameraMatrixR}\")\n",
    "print(f\"Left Distortion Coefficients:\\n{distL}\")\n",
    "print(f\"Right Distortion Coefficients:\\n{distR}\")\n",
    "print(f\"Rotation Matrix between cameras:\\n{R}\")\n",
    "print(f\"Translation Vector between cameras:\\n{T}\")\n",
    "\n",
    "# Save the parameters\n",
    "cv_file = cv.FileStorage('stereoParams.xml', cv.FILE_STORAGE_WRITE)\n",
    "cv_file.write(\"CameraMatrixL\", cameraMatrixL)\n",
    "cv_file.write(\"CameraMatrixR\", cameraMatrixR)\n",
    "cv_file.write(\"DistCoeffsL\", distL)\n",
    "cv_file.write(\"DistCoeffsR\", distR)\n",
    "cv_file.write(\"RotationMatrix\", R)\n",
    "cv_file.write(\"TranslationVector\", T)\n",
    "cv_file.write(\"EssentialMatrix\", E)\n",
    "cv_file.write(\"FundamentalMatrix\", F)\n",
    "cv_file.release()\n",
    "\n",
    "print(\"Parameters saved to 'stereoParams.xml'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
